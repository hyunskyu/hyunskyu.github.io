---
title: "Mean-Square Estimation (1) "
excerpt: "Estimation Theory 일부 정리"
use_math: true
---



고전적인 추정 이론은 다음과 같이 크게 3가지가 있다.

- Mean-Square Estimation
- Maximum-Likelihood Estimation
- Wiener Filtering

그 중에서 Mean-Square Estimation에 대한 내용을 적어보려 한다.  

# 1. Mean-Square Estimation

$x\in R^n$:  unknown vector

$z\in R^p$: x에 관련된 measurement 

$\hat{x}(z)$: $z$가 주어졌을 때의 추정된 $x$

$\tilde{x}=x-\hat{x}$ : Estimation error

$f_{xz}(x,z)$: Joint distribution

우리의 목적은 "관찰한 데이터를 가지고 추정한 값"($\hat{x}$)과 "실제로 추정하려는 값"($x$)의 "차이"($\tilde{x}$)를 이용하여 $\hat{x}$가  $x$를 잘 추정하고 있는지 확인하는 것이 목적이다.

이때 함수 $J$를 정의하고 $J$가 가장 최소가 되는 점을 미분을 통해 찾아주면 된다.

$J=E[C(\hat{x})]$        ($C(\cdot)$은 Cost function)

$=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}C(x-\hat{x})f_{x,z}(x,z)dxdz$

특히, Mean-Square Estimation은 Cost function을 $C(\tilde{x})=\tilde{x}^T\tilde{x}$ 로 정의하여 문제를 푸는 방법이다.

### 1.1 Mean-Square Estimation: General case

만약, Joint distribution $f\_{xz}(x,z)$를 알고 있을 때 $\hat{x}(z)$를 찾고자 한다면 함수 $J$는

$J=\int\int[x-\hat{x}]^T[x-\hat{x}]f_{xz}(x,z)dxdz$ 이고, Bayes rule에 따라서

$f\_{xz}(x,z)=f\_{x|z}(x|z)f\_z(z)$ 이므로 

$J=\int_{-\infty}^{\infty}f_z(z)\int_{-\infty}^{\infty}[x-\hat{x}(z)]^T[x-\hat{x}(z)]f_{x|z}(x|z)dxdz$ 가 된다.

그런데 $f_z(z)$는 non-negative function(distribution 성질)이기 때문에

결국 $\int_{-\infty}^{\infty}[x-\hat{x}(z)]^T[x-\hat{x}(z)]f_{x|z}(x|z)dx$ 부분이 최소가 되는 지점만을 찾으면 된다

이 식을 잘 보면 Conditional Expectation과 같다. 

따라서, 새로운 함수 $J'$를 다음과 같이 정의해주면,

$J'=\int_{-\infty}^{\infty}[x-\hat{x}(z)]^T[x-\hat{x}(z)]f_{x|z}(x|z)dx$ 

$=E\{[x-\hat{x}(z)]^T[x-\hat{x}(z)]/z\}$

$=E\{x^Tx/z\} -2\hat{x}(z)^TE\{x/z\}+\hat{x}(z)^T\hat{x}(z)$ 

$J'$를 최소화 시키기 위한 $\hat{x}(z)$는

$\cfrac{\partial J'}{\partial \hat{x}(z)}=-2E\{x/z\}+2\hat{x}(z)=0$

$\hat{x}_{MS}(z)=E\{x/z\}$ 

이다.

## 2. (Conditional) Error Mean and Covariance

아까 구한 추정된 값($\hat{x}$)이 유효한지를 보고싶은데, 그러기 위해서는 $x$와 $\hat{x}$의 차이인 $\tilde{x}$의 Mean 값이 0이 되어야 한다. (0의 의미하는 것은 추정된 값과 추정하고자 하는 값이 잘 맞아 떨어진다는 의미이다.)

위에서 말한 "관찰한 데이터를 가지고 추정한 값"($\hat{x}$)와 "실제로 추정하려는 값"($x$)의 "차이"($\tilde{x}$)를

다음과 같이 정의한다.

$\tilde{x}=x-\hat{x}_{MS}(z)$

그렇다면 $\tilde{x}$의 Mean과 Covariance는

### Mean

$E\{ \hat{x} \}=E\{x-\hat{x}_{MS}(z)\}$

$=E\{x-E\{x/z\}\}$

$=E\{x\}-E\{E\{x/z\}\}$ —————( $E\{x\}=E\{E\{x/z\}\}$이므로 )

$=E\{x\}-E\{x\}$

$=0$

### Covariance

$P_{\tilde{x}}=E\{\tilde{x}\tilde{x}^T\}$

$=E\{E\{\tilde{x}\tilde{x}^T/z\}\}$

$=E\{P_{x/z}\}$

### Computation of $E\{x/z\}$

앞서 구한 $\hat{x}_{MS}$는 다음과 같았다.

$E\{x/z\}=\int_{-\infty}^{\infty}xf_{x/z}(x/z)dx$ 

그런데 $f_{x/z}(x/z)$는 available한 data가 아니기 때문에 변형 시켜 계산해주어야 한다.

$\int_{-\infty}^{\infty}xf_{x/z}(x/z)dx$

$=\int_{-\infty}^{\infty}\cfrac{xf_{xz}(x,z)}{f_z(z)}dx$

$=\cfrac{\int_{-\infty}^{\infty}xf_{xz}(x,z)dx}{\int_{-\infty}^{\infty}f_{xz}(x,z)dx}$

$=\cfrac{\int_{-\infty}^{\infty}xf_{x/z}(x/z)f_x(x)dx}{\int_{-\infty}^{\infty}f_{x/z}(x/z)f_x(x)dx}$ 

최종적으로 만들어진 식은 처음에 봤던 식과는 다르게 $f_{x/z}(x/z)f_x(x)$부분이 available하다!

이제 몇 가지 특수한 케이스로 $\hat{x}_{MS}$를 구하는 법을 알아보자.

여기서 소개할 상황은

- Gaussian Conditional Mean and Covariance
- Conditional Mean for Linear Gaussian Measurement
- Linear Mean-Square Estimation

3가지 이다.

## 3. Gaussian Conditional Mean and Covariance

System state($x)$랑 Measurement($z$)가 다음과 같은 Gaussian의 형태를 띄고 있다면,

$x\sim N(\bar{x},P_x)$

$z\sim N(\bar{z},P_z)$

$y=\left[\begin{array}{l}x \\z\end{array}\right], \bar{y}=\left[\begin{array}{l}\bar{x} \\\bar{z}\end{array}\right], P_{Y}=\left[\begin{array}{ll}P_{x} & P_{x z} \\P_{z x} & P_{z}\end{array}\right]$

그러면, $f_y(y)$는 다음과 같다.

$f_{y}(y)=\cfrac{1}{\sqrt{(2 \pi)^{n+p}\left|P_{Y}\right|}} e^{-(1 / 2)(y-\bar{Y})^{T} P_{Y}^{-1}(y-\bar{Y})}$

이 식은 여전히 Gaussian의 형태를 띄고 있으며, $P_Y^{-1}$은 다음과 같이 알려져 있다.

$\begin{array}{l}P_{Y}^{-1}=\left[\begin{array}{cc}D^{-1} & -D^{-1} P_{x z} P_{z}^{-1} \\-P_{z}^{-1} P_{z x} D^{-1} & P_{z}^{-1}+P_{z}^{-1} P_{=x} D^{-1} P_{x z} P_{z}^{-1}\end{array}\right] \\D=P_{x}-P_{x=} P_{=}^{-1} P_{=x} \quad(\text { Schur complement })\end{array}$

우리는 앞 장에서 본 $E\{ x/z\}$를 다음과 같이 구할 수 있었다.

$E\{x/z\}=\cfrac{\int_{-\infty}^{\infty}xf_{x/z}(x/z)f_x(x)dx}{\int_{-\infty}^{\infty}f_{x/z}(x/z)f_x(x)dx}$

$f_{x/z}(x/z)$를 계산하면 $E\{x/z\}$를 쉽게(?) 찾을 수 있을 것 같다.

이제 $f_{x/z}(x/z)$를 찾아보자

$f_{x / z}(x / z)=\cfrac{f_{x z}(x, z)}{f_{z}(z)}=\cfrac{f_{Y}(y)}{f_{z}(z)}$

$=\cfrac{\sqrt{(2 \pi)^{p} \mid P_{z}} \mid}{\sqrt{(2 \pi)^{n+p}\left|P_{Y}\right|}} \exp \left\{-1 / 2\left[(y-\bar{Y})^{T} P_{Y}^{-1}(y-\bar{Y})-(z-\bar{z})^{T} P_{z}^{-1}(z-\bar{z})\right]\right\}$

여기서 뒷부분의 $[\ \ \ \ ]$부분은 다음과 같이 쓸 수 있다.

$\begin{array}{l}{\left[\begin{array}{l}x-\bar{x} \\z-\bar{z}\end{array}\right]^{T} P_{Y}^{-1}\left[\begin{array}{c}x-\bar{x} \\z-\bar{z}\end{array}\right]-(z-\bar{z})^{T} P_{z}^{-1}(z-\bar{z})} \\=(x-\bar{x})^{T} D^{-1}(x-\bar{x})-(x-\bar{x})^{T} D^{-1} P_{x z} P_{z}^{-1}(z-\bar{z})-(z-\bar{z})^{T} P_{z}^{-1} P_{z x} D^{-1}(x-\bar{x}) \\+(z-\bar{z})^{T}\left(P_{-}^{-1}+P_{-}^{-1} P_{-x} D^{-1} P_{r-} P_{-}^{-1}\right)(z-\bar{z})-(z-\bar{z})^{T} P_{-}^{-1}(z-\bar{z})\end{array}$$D=P_x-P_{xz}P_{z}^{-1}P_{zx}$ ———($schur\ complement$)

Conditional mean 과 Covariance를 다음과 같이 정의하자

$E\{x / z\}=\bar{x}+P_{x z} P_{z}^{-1}(z-\bar{z})$ —— Mean

$P_{x / z}=P_{x}-P_{x z} P_{z}^{-1} P_{z x}$ —— Covariance

그리고 둘을 이용해 위의 식을 정리하면,

$(x-\bar{x})^{T} D^{-1}(x-\bar{x})-(x-\bar{x})^{T} D^{-1} P_{x z} P_{z}^{-1}(z-\bar{z})-(z-\bar{z})^{T} P_{z}^{-1} P_{z x} D^{-1}(x-\bar{x}) \\+(z-\bar{z})^{T}\left(P_{-}^{-1}+P_{-}^{-1} P_{-x} D^{-1} P_{r-} P_{-}^{-1}\right)(z-\bar{z})-(z-\bar{z})^{T} P_{-}^{-1}(z-\bar{z})$

$=(x-E\{x / z\})^{T} P_{x / z}^{-1}(x-E\{x / z\})$

깔끔하게 정리된다.

그러면,

$f_{x / z}(x / z)=\cfrac{1}{\sqrt{(2 \pi)^{n}\left|P_{x / z}\right|}} \exp \left\{-\frac{1}{2}(x-E\{x / z\})^{T} P_{x / z}^{-1}(x-E\{x / z\})\right\}$

식을 보면 $x/z$는 여전히 Gaussian 의 형태인 것을 알 수 있다.

그러면 아까 정의했던 Mean과 Covariance가 타당함을 알 수있다.

그리하여, 최종적으로 다음과 같이 말할 수 있다.

만약 $x$ 와 $z$가 Gaussian일 때 $\hat{x}_{MS}(z)$는

$\hat{x}_{M S}(z)=E\{x / z\}=\bar{x}+P_{x z} P_{z}^{-1}(z-\bar{z})$ 이다.